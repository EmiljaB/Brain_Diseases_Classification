C:\Users\user\PycharmProjects\ThesisTest1\.venv\Scripts\python.exe C:\Users\user\PycharmProjects\ThesisTest1\MLP_BPTest.py
2024-05-18 22:56:57.960995: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-18 22:56:58.809848: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
100%|██████████| 32/32 [00:00<00:00, 2460.68it/s]
100%|██████████| 35/35 [00:00<00:00, 2506.54it/s]
100%|██████████| 30/30 [00:00<00:00, 2300.06it/s]
100%|██████████| 37/37 [00:00<00:00, 2173.61it/s]
100%|██████████| 30/30 [00:00<00:00, 1879.90it/s]
C:\Users\user\PycharmProjects\ThesisTest1\.venv\Lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2024-05-18 22:57:01.240928: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 1s 99ms/step - accuracy: 0.1645 - loss: 4.4827 - val_accuracy: 0.3030 - val_loss: 2.6086
Epoch 2/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3205 - loss: 1.9219 - val_accuracy: 0.1818 - val_loss: 2.1414
Epoch 3/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2673 - loss: 2.0817 - val_accuracy: 0.3333 - val_loss: 1.9695
Epoch 4/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.4959 - loss: 1.3130 - val_accuracy: 0.5455 - val_loss: 1.1303
Epoch 5/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.6540 - loss: 0.9254 - val_accuracy: 0.4242 - val_loss: 2.0982
Epoch 6/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6309 - loss: 1.0832 - val_accuracy: 0.5758 - val_loss: 0.8468
Epoch 7/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6874 - loss: 0.6943 - val_accuracy: 0.6364 - val_loss: 0.9222
Epoch 8/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.7838 - loss: 0.5311 - val_accuracy: 0.4848 - val_loss: 1.2487
Epoch 9/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.7641 - loss: 0.6916 - val_accuracy: 0.7879 - val_loss: 0.6512
Epoch 10/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.7252 - loss: 0.6272 - val_accuracy: 0.6061 - val_loss: 0.8483
Epoch 11/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.8644 - loss: 0.3559 - val_accuracy: 0.6364 - val_loss: 0.8831
Epoch 12/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.7549 - loss: 0.5446 - val_accuracy: 0.5455 - val_loss: 1.1485
Epoch 13/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.8674 - loss: 0.3846 - val_accuracy: 0.7879 - val_loss: 0.5749
Epoch 14/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.9009 - loss: 0.3277 - val_accuracy: 0.6061 - val_loss: 1.0542
Epoch 15/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.9421 - loss: 0.2361 - val_accuracy: 0.7273 - val_loss: 0.9477
Epoch 16/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.9646 - loss: 0.2094 - val_accuracy: 0.8182 - val_loss: 0.5268
Epoch 17/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.9268 - loss: 0.2157 - val_accuracy: 0.6364 - val_loss: 0.7088
Epoch 18/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.9664 - loss: 0.1758 - val_accuracy: 0.7576 - val_loss: 0.6932
Epoch 19/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.9784 - loss: 0.1520 - val_accuracy: 0.7273 - val_loss: 0.6069
Epoch 20/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.9936 - loss: 0.1118 - val_accuracy: 0.7273 - val_loss: 0.6208
Epoch 21/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.9962 - loss: 0.0987 - val_accuracy: 0.7273 - val_loss: 0.6527
Epoch 22/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.9836 - loss: 0.0957 - val_accuracy: 0.6970 - val_loss: 0.5960
Epoch 23/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.9810 - loss: 0.1165 - val_accuracy: 0.7576 - val_loss: 0.5413
Epoch 24/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.9732 - loss: 0.1339 - val_accuracy: 0.6970 - val_loss: 0.6776
Epoch 25/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.9888 - loss: 0.0920 - val_accuracy: 0.7879 - val_loss: 0.6292
Epoch 26/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.9862 - loss: 0.0886 - val_accuracy: 0.7879 - val_loss: 0.5476
Epoch 27/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.9828 - loss: 0.0779 - val_accuracy: 0.7576 - val_loss: 0.5579
Epoch 28/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.9824 - loss: 0.0920 - val_accuracy: 0.7879 - val_loss: 0.5614
Epoch 29/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 1.0000 - loss: 0.0636 - val_accuracy: 0.7576 - val_loss: 0.7438
Epoch 30/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 1.0000 - loss: 0.0620 - val_accuracy: 0.7879 - val_loss: 0.6046
Epoch 31/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.9944 - loss: 0.0598 - val_accuracy: 0.6667 - val_loss: 0.7694
Epoch 32/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.9866 - loss: 0.0628 - val_accuracy: 0.7576 - val_loss: 0.6808
Epoch 33/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 1.0000 - loss: 0.0584 - val_accuracy: 0.7273 - val_loss: 0.6972
Epoch 34/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 1.0000 - loss: 0.0410 - val_accuracy: 0.7576 - val_loss: 0.5527
Epoch 35/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 1.0000 - loss: 0.0426 - val_accuracy: 0.7273 - val_loss: 0.6505
Epoch 36/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 1.0000 - loss: 0.0433 - val_accuracy: 0.7576 - val_loss: 0.6545
Epoch 37/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 1.0000 - loss: 0.0401 - val_accuracy: 0.7273 - val_loss: 0.6539
Epoch 38/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.9962 - loss: 0.0396 - val_accuracy: 0.6667 - val_loss: 0.6593
Epoch 39/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 1.0000 - loss: 0.0291 - val_accuracy: 0.7879 - val_loss: 0.5738
Epoch 40/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 1.0000 - loss: 0.0291 - val_accuracy: 0.7576 - val_loss: 0.6824
Epoch 41/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.9944 - loss: 0.0369 - val_accuracy: 0.7879 - val_loss: 0.6280
Epoch 42/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 1.0000 - loss: 0.0410 - val_accuracy: 0.6970 - val_loss: 0.6105
Epoch 43/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 1.0000 - loss: 0.0303 - val_accuracy: 0.6667 - val_loss: 0.7671
Epoch 44/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 1.0000 - loss: 0.0310 - val_accuracy: 0.7273 - val_loss: 0.7020
Epoch 45/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 1.0000 - loss: 0.0242 - val_accuracy: 0.7576 - val_loss: 0.6956
Epoch 46/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 1.0000 - loss: 0.0217 - val_accuracy: 0.6970 - val_loss: 0.7448
Epoch 47/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 1.0000 - loss: 0.0201 - val_accuracy: 0.6970 - val_loss: 0.7233
Epoch 48/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 1.0000 - loss: 0.0238 - val_accuracy: 0.6970 - val_loss: 0.6911
Epoch 49/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 0.7273 - val_loss: 0.6697
Epoch 50/50
5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.7273 - val_loss: 0.7085
2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step
2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7244 - loss: 0.7157
Test Accuracy: 0.7272727489471436
Precision: 0.7931096681096681
Recall: 0.7272727272727273
F1 Score: 0.7172235172235172

Process finished with exit code 0
